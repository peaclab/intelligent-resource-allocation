{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920377f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae8354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "093d12cb",
   "metadata": {},
   "source": [
    "# Eagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2018-11-14'\n",
    "end_time = '2023-02-01'\n",
    "target_feature = 'run_time' \n",
    "models = ['baseline', 'clustering_xgb','clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "bias_types = ['none', 'two_sigma']\n",
    "\n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='7D')\n",
    "window_sizes = [7, 14]\n",
    "\n",
    "eagle_results = {}\n",
    "\n",
    "for start_date in start_dates:\n",
    "    eagle_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        eagle_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            eagle_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                eagle_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/eagle/window_size={window_size}/eagle_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                if os.path.exists(file_path):\n",
    "                    eagle_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "  \n",
    "                else:\n",
    "                    print(f\"Error: The file {file_path} was not found.\")\n",
    "    \n",
    "    \n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='1M')\n",
    "window_sizes = [30, 60, 90]\n",
    "\n",
    "for start_date in start_dates:\n",
    "    eagle_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        eagle_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            eagle_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                eagle_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/eagle/window_size={window_size}/eagle_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                eagle_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "              \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43292c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for start_date, window_data in eagle_results.items():\n",
    "    for window_size, model_data in window_data.items():\n",
    "        for model, bias_data in model_data.items():\n",
    "            for bias_type, result in bias_data.items():\n",
    "                if isinstance(result, pd.DataFrame) and {'req', 'act', 'pred'}.issubset(result.columns):\n",
    "                    for _, row in result.iterrows():\n",
    "                        data.append({\n",
    "                            'start_date': start_date,\n",
    "                            'window_size': window_size,\n",
    "                            'model': model,\n",
    "                            'bias_type': bias_type,\n",
    "                            'req': row['req'],\n",
    "                            'act': row['act'],\n",
    "                            'pred': row['pred']\n",
    "                        })\n",
    "                else:\n",
    "                    print(f\"Warning: Missing expected columns in result for {start_date}, {window_size}, {model}, {bias_type}\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_parquet('eagle_results.parquet', engine='pyarrow', index=False)\n",
    "\n",
    "print(\"Saved eagle_results to eagle_results.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeeed36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc8e6e62",
   "metadata": {},
   "source": [
    "# BU SCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08928585",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2022-12-31'\n",
    "end_time = '2023-12-31'\n",
    "target_feature = ['execution_time'] \n",
    "models = ['baseline', 'clustering_xgb','clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "bias_types = ['none', 'two_sigma']\n",
    "\n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='7D')\n",
    "window_sizes = [7, 14]\n",
    "\n",
    "\n",
    "bu_scc_results = {}\n",
    "\n",
    "for start_date in start_dates:\n",
    "    bu_scc_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        bu_scc_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            bu_scc_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                bu_scc_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/bu_scc/window_size={window_size}/bu_scc_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                bu_scc_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='1M')\n",
    "window_sizes = [30, 60, 90]\n",
    "for start_date in start_dates:\n",
    "    bu_scc_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        bu_scc_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            bu_scc_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                bu_scc_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/bu_scc/window_size={window_size}/bu_scc_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                bu_scc_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0d6eb",
   "metadata": {},
   "source": [
    "# Fugaku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2024-04-05'\n",
    "end_time = '2024-04-30'\n",
    "target_feature = ['duration'] \n",
    "models = ['baseline', 'clustering_xgb','clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "bias_types = ['none', 'two_sigma']\n",
    "\n",
    "\n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='7D')\n",
    "window_sizes = [7, 14]\n",
    "\n",
    "fugaku_results = {}\n",
    "\n",
    "for start_date in start_dates:\n",
    "    fugaku_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        fugaku_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            fugaku_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                fugaku_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/fugaku/window_size={window_size}/fugaku_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                fugaku_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='3D')\n",
    "window_sizes = [3]\n",
    "\n",
    "for start_date in start_dates:\n",
    "    fugaku_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        fugaku_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            fugaku_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                fugaku_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/fugaku/window_size={window_size}/fugaku_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                fugaku_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "              \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da9211",
   "metadata": {},
   "source": [
    "# M100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2021-12-01'\n",
    "end_time = '2021-12-31'\n",
    "target_feature = ['execution_time'] \n",
    "models = ['baseline', 'clustering_xgb','clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "bias_types = ['none', 'two_sigma']\n",
    "\n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='7D')\n",
    "window_sizes = [7, 14]\n",
    "\n",
    "m100_results = {}\n",
    "\n",
    "for start_date in start_dates:\n",
    "    m100_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        m100_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            m100_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                m100_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/m100/window_size={window_size}/m100_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                m100_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='3D')\n",
    "window_sizes = [3]\n",
    "for start_date in start_dates:\n",
    "    m100_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        m100_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            m100_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                m100_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/m100/window_size={window_size}/m100_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                m100_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625c1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01ab8cf7",
   "metadata": {},
   "source": [
    "# Sandia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2024-05-01'\n",
    "end_time = '2024-09-23'\n",
    "target_feature = ['execution_time']\n",
    "models = ['baseline', 'clustering_xgb','clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "bias_types = ['none', 'two_sigma']\n",
    "\n",
    "\n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='7D')\n",
    "window_sizes = [7, 14]\n",
    "\n",
    "sandia_results = {}\n",
    "\n",
    "for start_date in start_dates:\n",
    "    sandia_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        sandia_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            sandia_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                sandia_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/sandia/window_size={window_size}/sandia_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                sandia_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='1M')\n",
    "window_sizes = [30]\n",
    "\n",
    "for start_date in start_dates:\n",
    "    sandia_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        sandia_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            sandia_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                sandia_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/sandia/window_size={window_size}/sandia_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                sandia_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "              \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='7D')\n",
    "\n",
    "for model in models:\n",
    "    for bias in bias_types:\n",
    "        total_underpred = 0\n",
    "        total_jobs = 0\n",
    "\n",
    "        for start_date in start_dates:\n",
    "            start_date = pd.Timestamp(start_date)\n",
    "\n",
    "            df = sandia_results[start_date].get(7, {}).get(model, {}).get(bias)\n",
    "\n",
    "            if df is None:\n",
    "                continue\n",
    "                \n",
    "            df = df.copy()\n",
    "            underpredictions = df[df['pred'] < df['act']].copy()\n",
    "            total_underpred = total_underpred + len(underpredictions)\n",
    "            total_jobs = total_jobs +  len(df)\n",
    "            \n",
    "        success_rate = 100 * (1 - total_underpred / total_jobs)\n",
    "        underpred_ratio = 100 * (total_underpred / total_jobs)\n",
    "\n",
    "        print(f\"Model name: {model}, Bias type: {bias}, UR: {underpred_ratio}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6fcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b245755d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88248475",
   "metadata": {},
   "source": [
    "# ALL Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_metrics(dictionary, start_time, end_time, input_freq, window_size, df_name):\n",
    "    models = ['baseline', 'clustering_xgb', 'clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "    bias_types = ['none', 'two_sigma']\n",
    "\n",
    "    start_dates = pd.date_range(start=start_time, end=end_time, freq=input_freq)\n",
    "    results = []\n",
    "\n",
    "    available_dates = list(dictionary.keys())  # Store available keys for debugging\n",
    "\n",
    "    for model in models:\n",
    "        for bias in bias_types:\n",
    "            total_underpred = 0\n",
    "            total_jobs = 0\n",
    "            total_user_req = 0\n",
    "            total_pred = 0\n",
    "            underpred_counts = []  # List to store underprediction counts for each date\n",
    "\n",
    "            for start_date in start_dates:\n",
    "                start_date = pd.Timestamp(start_date)\n",
    "\n",
    "                if window_size not in dictionary[start_date]:\n",
    "                    print(f\"Missing window_size {window_size} for {start_date}\")\n",
    "                    continue\n",
    "\n",
    "                df = dictionary[start_date][window_size][model][bias]\n",
    "\n",
    "                underpredictions = df[df['pred'] < df['act']]\n",
    "                underpred_counts.append(len(underpredictions))  # Store underpredictions count for this date\n",
    "                total_underpred += len(underpredictions)\n",
    "                total_jobs += len(df)\n",
    "\n",
    "                user_overpred = df[df['act'] < df['req']]\n",
    "                total_user_req += (user_overpred['req'] - user_overpred['act']).sum()\n",
    "\n",
    "                overpred = df[df['act'] < df['pred']]\n",
    "                total_pred += (overpred['pred'] - overpred['act']).sum()\n",
    "\n",
    "            # Calculate mean and standard deviation of underpredictions\n",
    "            if underpred_counts:  # Ensure the list is not empty\n",
    "                mean_underpred = sum(underpred_counts) / len(underpred_counts)\n",
    "                std_underpred = pd.Series(underpred_counts).std()\n",
    "            else:\n",
    "                mean_underpred = 0\n",
    "                std_underpred = 0\n",
    "\n",
    "            if total_jobs > 0:\n",
    "                success_rate = 100 * (1 - total_underpred / total_jobs)\n",
    "                underpred_ratio = 100 * (total_underpred / total_jobs)\n",
    "            else:\n",
    "                success_rate = 0\n",
    "                underpred_ratio = 0\n",
    "\n",
    "            result_entry = {\n",
    "                \"DataFrame\": df_name,\n",
    "                \"Model\": model,\n",
    "                \"Bias\": bias,\n",
    "                \"Success Rate (%)\": round(success_rate, 2),\n",
    "                \"Underprediction Ratio (%)\": round(underpred_ratio, 2),\n",
    "                \"Total User Request Overprediction (hours)\": round(total_user_req / 3600, 2),\n",
    "                \"Total Model Overprediction (hours)\": round(total_pred / 3600, 2),\n",
    "                \"Mean Underprediction Count\": round(mean_underpred, 2),\n",
    "                \"Std Underprediction Count\": round(std_underpred, 2)\n",
    "            }\n",
    "\n",
    "            results.append(result_entry)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e770d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "datasets = [(\"Eagle\", eagle_results,'2018-11-14','2023-02-01','1M','30'),\n",
    "            (\"BU SCC\", bu_scc_results,'2022-12-31','2023-12-31','1M','60'), \n",
    "            (\"Fugaku\", fugaku_results,'2024-04-05','2024-04-30','3D','3'),\n",
    "            (\"M100\", m100_results,'2021-12-01','2021-12-31' ,'3D','3')]\n",
    "#(\"Sandia\", sandia_results,'2024-05-01','2024-09-23','7D','7')\n",
    "\n",
    "for df_name, dictionary, start_time, end_time, input_freq, window_size in datasets:\n",
    "    window_size = int(window_size.replace('D', '').replace('M', ''))\n",
    "    df_results = find_metrics(dictionary, start_time, end_time, input_freq, window_size, df_name)\n",
    "    all_results.append(df_results)\n",
    "\n",
    "final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import to_rgb\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "'''\n",
    "Possible values are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, \n",
    "BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, \n",
    "OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, \n",
    "Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, \n",
    "Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, \n",
    "Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn,\n",
    "YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, \n",
    "binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cividis, cividis_r, cool, cool_r, coolwarm, \n",
    "coolwarm_r, copper, copper_r, crest, crest_r, cubehelix, cubehelix_r, flag, flag_r, flare, flare_r, \n",
    "gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, \n",
    "gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, \n",
    "gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, icefire, icefire_r, inferno, inferno_r, \n",
    "jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, CMRmap, ocean_r, pink, pink_r, \n",
    "plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spring,\n",
    "spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, \n",
    "terrain, terrain_r, twilight, twilight_r, twilight_shifted, twilight_shifted_r, viridis, viridis_r,\n",
    "vlag, vlag_r, winter, winter_r\n",
    "'''\n",
    "base_colors = sns.color_palette(\"Dark2\", 6)\n",
    "\n",
    "filtered_df = final_results_df[final_results_df[\"Bias\"] == \"two_sigma\"]\n",
    "\n",
    "datasets = filtered_df[\"DataFrame\"].unique()\n",
    "models = filtered_df[\"Model\"].unique()\n",
    "\n",
    "x_labels = {\n",
    "    \"baseline - User Request\": \"User Requested\",\n",
    "    \"baseline\": r'Single-XGB + $2\\sigma$',\n",
    "    \"clustering_xgb\": r'Clustering-XGB + $2\\sigma$',\n",
    "    \"clustering_rf\": r'Clustering-RF + $2\\sigma$',\n",
    "    \"resampled_xgb\": r'Resampling-XGB + $2\\sigma$',\n",
    "    \"resampled_rf\": r'Resampling-RF + $2\\sigma$',\n",
    "}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(16,4))\n",
    "axes = axes.flatten() \n",
    "\n",
    "\n",
    "for idx, df_name in enumerate(datasets):\n",
    "\n",
    "    user_requested_hours_df = []\n",
    "    model_overprediction_hours_df = []\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        df_subset = filtered_df[(filtered_df[\"DataFrame\"] == df_name) & (filtered_df[\"Model\"] == model)]\n",
    "        \n",
    "        user_requested_hours_df.append(df_subset[\"Total User Request Overprediction (hours)\"].sum())\n",
    "        \n",
    "        model_overprediction_hours_df.append(df_subset[\"Total Model Overprediction (hours)\"].sum())\n",
    "        \n",
    "\n",
    "        ratio = df_subset[\"Total User Request Overprediction (hours)\"].sum()/df_subset[\"Total Model Overprediction (hours)\"].sum() \n",
    "\n",
    "        print(f\"Dataset: {df_name}, Model: {model}, Ratio: {ratio:.2f}\")\n",
    "        \n",
    "    \n",
    "    ax = axes[idx]\n",
    "\n",
    "    x = np.arange(6)\n",
    "    width = 0.5\n",
    "    bars_user_request = []\n",
    "    bars_model_overprediction = []\n",
    "    \n",
    "    bars_user_request.append(ax.bar(x[0], user_requested_hours_df[0], width, color=base_colors[0], alpha=0.7))\n",
    "\n",
    "\n",
    "    for i, model in enumerate(models):        \n",
    "        bars_model_overprediction.append(ax.bar(x[i+1], model_overprediction_hours_df[i], width, \n",
    "                                                color=base_colors[i+1], alpha=0.7))\n",
    "    \n",
    "    \n",
    "    #ax.set_xlabel(\"Model Name\",fontsize=16)\n",
    "    ax.set_ylabel(\"Total Overpredicted Hours\",fontsize=16)\n",
    "    ax.set_title(f\"{df_name}\",fontsize=16)\n",
    "    ax.set_xticks([])\n",
    "    #ax.set_xticks(x)\n",
    "    #ax.set_xticklabels([x_labels[\"baseline - User Request\"]] + [x_labels[m] for m in models], fontsize=12)\n",
    "    #ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "\n",
    "handles_user_request = [bar for bar in bars_user_request]\n",
    "handles_model_overprediction = [bar for bar in bars_model_overprediction[:5]]  # One per model\n",
    "\n",
    "labels_user_request = [\"User Requested\"]\n",
    "labels_model_overprediction = [x_labels[model] for model in models]\n",
    "\n",
    "fig.legend(handles_user_request + handles_model_overprediction, \n",
    "           labels_user_request + labels_model_overprediction,\n",
    "           title='Model Name',title_fontsize='14',loc=\"upper center\", bbox_to_anchor=(0.5, 1.3), ncol=3, fontsize=14)\n",
    "\n",
    "\n",
    "fig.suptitle(\"User Request vs Model Execution Time Overprediction Hours\", fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plot_name = 'exec_time_overpred.svg'\n",
    "file_path = os.path.join('/projectnb/peaclab-mon/boztop/resource-allocation/plots', plot_name)\n",
    "plt.savefig(file_path, format=\"svg\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce53d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e35304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a2357f3",
   "metadata": {},
   "source": [
    "# Other Resource Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2024-04-05'\n",
    "end_time = '2024-04-30'\n",
    "target_feature = ['cnumut'] \n",
    "models = ['baseline', 'clustering_xgb','clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "bias_types = ['none', 'two_sigma']\n",
    "\n",
    "\n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='7D')\n",
    "window_sizes = [7, 14]\n",
    "\n",
    "fugaku_cpu_results = {}\n",
    "\n",
    "for start_date in start_dates:\n",
    "    fugaku_cpu_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        fugaku_cpu_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            fugaku_cpu_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                fugaku_cpu_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/fugaku/cpu_pred/window_size={window_size}/fugaku_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                fugaku_cpu_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='3D')\n",
    "window_sizes = [3]\n",
    "\n",
    "for start_date in start_dates:\n",
    "    fugaku_cpu_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        fugaku_cpu_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            fugaku_cpu_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                fugaku_cpu_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/fugaku/cpu_pred/window_size={window_size}/fugaku_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                fugaku_cpu_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "              \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2024-04-05'\n",
    "end_time = '2024-04-30'\n",
    "target_feature = ['mmszu'] \n",
    "models = ['baseline', 'clustering_xgb','clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "bias_types = ['none', 'two_sigma']\n",
    "\n",
    "\n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='7D')\n",
    "window_sizes = [7, 14]\n",
    "\n",
    "fugaku_mem_results = {}\n",
    "\n",
    "for start_date in start_dates:\n",
    "    fugaku_mem_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        fugaku_mem_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            fugaku_mem_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                fugaku_mem_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/fugaku/mem_pred/window_size={window_size}/fugaku_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                fugaku_mem_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "start_dates = pd.date_range(start=start_time, end=end_time, freq='3D')\n",
    "window_sizes = [3]\n",
    "\n",
    "for start_date in start_dates:\n",
    "    fugaku_mem_results[start_date] = {}\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        fugaku_mem_results[start_date][window_size] = {}\n",
    "\n",
    "        for model in models:\n",
    "            fugaku_mem_results[start_date][window_size][model] = {}\n",
    "\n",
    "            for bias_type in bias_types:\n",
    "                fugaku_mem_results[start_date][window_size][model][bias_type] = {}\n",
    "\n",
    "                file_path = f'/projectnb/peaclab-mon/boztop/resource-allocation/exp_results/fugaku/mem_pred/window_size={window_size}/fugaku_{model}_bias_{bias_type}_{target_feature}_window_{window_size}_days_{start_date}.pkl' \n",
    "                fugaku_mem_results[start_date][window_size][model][bias_type] = pd.read_pickle(file_path) \n",
    "                \n",
    "              \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e49b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [(\"Fugaku_cpu\", fugaku_cpu_results, '2024-04-05', '2024-04-30', '3D', '3'), \n",
    "            (\"Fugaku_mem\", fugaku_mem_results, '2024-04-05', '2024-04-30', '3D', '3')]\n",
    "\n",
    "models = ['baseline', 'clustering_xgb', 'clustering_rf', 'resampled_xgb', 'resampled_rf']\n",
    "bias_types = ['two_sigma']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for df_name, dictionary, start_time, end_time, input_freq, window_size in datasets:\n",
    "    window_size = int(window_size.replace('D', '').replace('M', '')) \n",
    "    \n",
    "    if 'cpu' in df_name.lower():\n",
    "        results['cpu'] = {}\n",
    "    elif 'mem' in df_name.lower(): \n",
    "        results['mem'] = {}\n",
    "\n",
    "    for model in models:\n",
    "        if 'cpu' in df_name.lower():\n",
    "            results['cpu'][model] = {}\n",
    "        elif 'mem' in df_name.lower(): \n",
    "            results['mem'][model] = {}\n",
    "\n",
    "        for bias in bias_types:\n",
    "            cpu_results = []\n",
    "            mem_results = []\n",
    "\n",
    "            for start_date in start_dates:\n",
    "                start_date = pd.Timestamp(start_date) \n",
    "\n",
    "                df = dictionary[start_date][window_size][model][bias]\n",
    "                df['start_date'] = start_date\n",
    "                df['model'] = model\n",
    "                df['bias'] = bias\n",
    "\n",
    "                if 'cpu' in df_name.lower():\n",
    "                    df[f'cpu_overprediction_{model}'] = df['pred'] / df['act']\n",
    "                    df[f'cpu_overprediction_user_req'] = df['req'] / df['act']\n",
    "                    cpu_results.append(df) \n",
    "                elif 'mem' in df_name.lower(): \n",
    "                    df[f'mem_overprediction_{model}'] = df['pred'] / df['act'] \n",
    "                    df[f'mem_overprediction_user_req'] = df['req'] / df['act']\n",
    "                    mem_results.append(df) \n",
    "            \n",
    "            if 'cpu' in df_name.lower():\n",
    "                cpu_df = pd.concat(cpu_results, axis=0, ignore_index=True)\n",
    "                results['cpu'][model][bias] = cpu_df\n",
    "            elif 'mem' in df_name.lower(): \n",
    "                mem_df = pd.concat(mem_results, axis=0, ignore_index=True)\n",
    "                results['mem'][model][bias] = mem_df\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_models = {\n",
    "    \n",
    "    'baseline' : r'Single-XGB + 2$\\sigma$',\n",
    "    'clustering_xgb' : r'Clustering-XGB + 2$\\sigma$',\n",
    "    'clustering_rf' : r'Clustering-RF + 2$\\sigma$',\n",
    "    'resampled_xgb' : r'Resampling-XGB + 2$\\sigma$',\n",
    "    'resampled_rf' : r'Resampling-RF + 2$\\sigma$'\n",
    "}\n",
    "\n",
    "colors = sns.color_palette(\"Dark2\", 15)\n",
    "def plot_overestimation_mem_kde(dictionary, \n",
    "                                title='Fugaku Dataset Resource Prediction Overestimation Results'):\n",
    "    \n",
    "    resources = ['mem', 'cpu']\n",
    "    titles = ['Maximum Memory Size (Bytes) Prediction', 'Number of Processors Prediction']\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16,5))\n",
    "    \n",
    "    i = 0\n",
    "    j = 1\n",
    "    for resource in resources:\n",
    "        for model in models:\n",
    "            df = dictionary[resource][model]['two_sigma']\n",
    "            \n",
    "            if model == 'baseline':\n",
    "                sns.kdeplot(df[f'{resource}_overprediction_user_req'], label='User Requested Values', fill=True, alpha=0.6, linewidth=2, log_scale=True, color=colors[0], ax=axs[i])\n",
    "            sns.kdeplot(df[f'{resource}_overprediction_{model}'], label=rename_models[model], fill=True, alpha=0.6, linewidth=2, log_scale=True, color=colors[j], ax=axs[i])\n",
    "            j = j + 1\n",
    "        \n",
    "        axs[i].axvline(1, color='red', linestyle='--', label='Perfect Match (Ratio=1)')\n",
    "        axs[i].set_xscale('log')\n",
    "        axs[i].set_title(f\"{titles[i]}\", fontsize=14)\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].set_ylabel('Density', fontsize=16)\n",
    "        axs[i].grid(True)\n",
    "\n",
    "        i=1\n",
    "        j=1\n",
    "\n",
    "    fig.suptitle(title, fontsize=20,y=1.01)\n",
    "    \n",
    "    # Place the legend only once outside the subplots, with no overlapping\n",
    "    handles, labels = axs[0].get_legend_handles_labels()  # Get handles and labels from the first subplot\n",
    "    fig.legend(handles, labels, title='Model Name', title_fontsize='14', loc='upper center', fontsize=14, bbox_to_anchor=(0.415, 1.31), ncol=3)\n",
    "\n",
    "    fig.text(0.5, 0.04, 'Overestimation Factor (Predicted/Actual)', ha='center', fontsize=16)\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plot_name = 'memory_cpu_OF_density.svg'\n",
    "    file_path = os.path.join('/projectnb/peaclab-mon/boztop/resource-allocation/plots', plot_name)\n",
    "    plt.savefig(file_path, format=\"svg\", dpi=300, bbox_inches='tight')  \n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overestimation_mem_kde(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rename_models = {\n",
    "    'baseline': r'Single-XGB + 2$\\sigma$',\n",
    "    'clustering_xgb': r'Clustering-XGB + 2$\\sigma$',\n",
    "    'clustering_rf': r'Clustering-RF + 2$\\sigma$',\n",
    "    'resampled_xgb': r'Resampling-XGB + 2$\\sigma$',\n",
    "    'resampled_rf': r'Resampling-RF + 2$\\sigma$'\n",
    "}\n",
    "\n",
    "colors = sns.color_palette(\"Dark2\", 15)\n",
    "\n",
    "def plot_overestimation_mem_ridgeline(dictionary, \n",
    "                                      title='Fugaku Dataset Resource Prediction Overestimation Results'):\n",
    "    resources = ['mem', 'cpu']\n",
    "    titles = ['Maximum Memory Size (Bytes) Prediction', 'Number of Processors Prediction']\n",
    "\n",
    "    for i, resource in enumerate(resources):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        models_sorted = ['baseline'] + [m for m in rename_models if m != 'baseline']\n",
    "        \n",
    "        for j, model in enumerate(models_sorted):\n",
    "            df = dictionary[resource][model]['two_sigma']\n",
    "            data = df[f'{resource}_overprediction_{model}']\n",
    "            \n",
    "            # KDE plot offset vertically for ridgeline effect\n",
    "            sns.kdeplot(data, fill=True, alpha=0.7, linewidth=1.5, log_scale=True, color=colors[j])\n",
    "            \n",
    "            # Adding model labels on the right side\n",
    "            plt.text(data.median(), j * 0.3 + 0.5, rename_models[model] if model != 'baseline' else 'User Requested Values', \n",
    "                     fontsize=12, color=colors[j], verticalalignment='bottom')\n",
    "\n",
    "        plt.axvline(1, color='red', linestyle='--', label='Perfect Match (Ratio=1)')\n",
    "        plt.xscale('log')\n",
    "        plt.title(titles[i], fontsize=14)\n",
    "        plt.xlabel('Overestimation Factor (Predicted/Actual)', fontsize=12)\n",
    "        plt.ylabel('Density', fontsize=12)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save each figure separately\n",
    "        plot_name = f'{resource}_overestimation_ridgeline.svg'\n",
    "        file_path = os.path.join('/projectnb/peaclab-mon/boztop/resource-allocation/plots', plot_name)\n",
    "        plt.savefig(file_path, format=\"svg\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overestimation_mem_ridgeline(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07db44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
